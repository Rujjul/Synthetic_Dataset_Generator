{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN2Fxt1e9FXSSgIVoxc83hL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rujjul/Synthetic_Dataset_Generator/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Synthetic_Dataset_Generator"
      ],
      "metadata": {
        "id": "AfuqJBVwAXjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "MUFzQjgIB-xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import os\n",
        "import requests\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "9A__7DHJAeAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LLM Model\n",
        "\n",
        "LLAMA = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""
      ],
      "metadata": {
        "id": "VhVABP1FDcF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Quant config\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "load_in_4bit=True,\n",
        "bnb_4bit_use_double_quant=True,\n",
        "bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "bnb_4bit_quant_type=\"nf4\"\n",
        ")"
      ],
      "metadata": {
        "id": "8vsysrRtMqna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "You are a helpful assistant who generates synthetic data based on the user's demand and scenario. The user will provide you with the number of rows, the column names with their respective data types, and some other parameters or constraints if necessary. If you are not able to provide any data regarding something just directly mention that you are unable to do so. Tehn the user will either update or modify their prompt. Do not provide a python script to generate the data. Provide the data as a json with arrays.\n",
        "\"\"\"\n",
        "\n",
        "user_prompt = f\"\"\"\n",
        "Create a synthetic dataset for an offical document.\n",
        "Column names and type-\n",
        "Number of rows: 5\n",
        "Name: not more than 13 alphabets\n",
        "Phone Number: 10 digit number\n",
        "Age: not more than 2 digit number\n",
        "Occupation: 30 alphabets\n",
        "PAN ID: 12 alphanumeric characters\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"content\": user_prompt}\n",
        "  ]\n"
      ],
      "metadata": {
        "id": "FWxAl1sRD4cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(LLAMA)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
        "model = AutoModelForCausalLM.from_pretrained(LLAMA, device_map=\"auto\", quantization_config=quant_config)\n",
        "outputs = model.generate(inputs, max_new_tokens=2000)"
      ],
      "metadata": {
        "id": "o0Zn5T5bJTU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = tokenizer.decode(outputs[0])"
      ],
      "metadata": {
        "id": "Nvd5FlL0RdkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response))"
      ],
      "metadata": {
        "id": "7WyL3n-nSF-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "z02LDtN-QGWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract assistant's response\n",
        "\n",
        "assistant_response = response.split(\"assistant\")[-1].strip()"
      ],
      "metadata": {
        "id": "3bTa2yzAOlMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_and_parse_json(assistant_response):\n",
        "    \"\"\"Extract JSON from LLM response and parse it\"\"\"\n",
        "    try:\n",
        "        # Remove markdown code fences if present\n",
        "        if \"```json\" in assistant_response:\n",
        "            json_str = assistant_response.split(\"```json\")[1].split(\"```\")[0]\n",
        "        elif \"```\" in assistant_response:\n",
        "            json_str = assistant_response.split(\"```\")[1].split(\"```\")[0]\n",
        "        else:\n",
        "            json_str = assistant_response\n",
        "\n",
        "        # Parse JSON\n",
        "        data = json.loads(json_str.strip())\n",
        "\n",
        "        # Format nicely\n",
        "        formatted_json = json.dumps(data, indent=2)\n",
        "        status = f\"âœ“ Successfully generated {len(data)} rows of data!\"\n",
        "\n",
        "        return status, formatted_json, data\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"âš  Error parsing JSON: {str(e)}\", assistant_response, None"
      ],
      "metadata": {
        "id": "rknB7ETvRCgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset():\n",
        "    \"\"\"Generate synthetic dataset based on user inputs\"\"\"\n",
        "\n",
        "    # Extract and parse JSON using separate function\n",
        "    return extract_and_parse_json(assistant_response)\n"
      ],
      "metadata": {
        "id": "ysYDy3WxR3Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(title=\"Synthetic Dataset Generator\") as demo:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ðŸŽ² Synthetic Dataset Generator\n",
        "    ### Powered by Llama 3.1 (4-bit quantized)\n",
        "    Generate custom synthetic datasets by specifying columns and constraints\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            num_rows = gr.Slider(\n",
        "                minimum=1,\n",
        "                maximum=100,\n",
        "                value=5,\n",
        "                step=1,\n",
        "                label=\"Number of Rows\"\n",
        "            )\n",
        "\n",
        "            columns_info = gr.Textbox(\n",
        "                label=\"Column Specifications\",\n",
        "                placeholder=\"Example:\\n- Name: max 13 alphabets\\n- Phone Number: 10 digits\\n- Age: max 2 digits\",\n",
        "                lines=8,\n",
        "                value=\"- Name: max 13 alphabets\\n- Phone Number: 10 digits\\n- Age: max 2 digits\\n- Occupation: max 30 alphabets\\n- PAN ID: 12 alphanumeric characters\"\n",
        "            )\n",
        "\n",
        "            additional_constraints = gr.Textbox(\n",
        "                label=\"Additional Constraints (Optional)\",\n",
        "                placeholder=\"Example: All names should be Indian names, Age between 18-65\",\n",
        "                lines=3\n",
        "            )\n",
        "\n",
        "            generate_btn = gr.Button(\"ðŸš€ Generate Dataset\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "        with gr.Column():\n",
        "            status_text = gr.Textbox(\n",
        "                label=\"Status\",\n",
        "                lines=2\n",
        "            )\n",
        "\n",
        "            output_json = gr.Code(\n",
        "                label=\"Generated Dataset (JSON)\",\n",
        "                language=\"json\",\n",
        "                lines=15\n",
        "            )\n",
        "\n",
        "            output_data = gr.JSON(\n",
        "                label=\"Preview\",\n",
        "                visible=True\n",
        "            )\n",
        "\n",
        "    # Examples\n",
        "    gr.Markdown(\"### ðŸ“‹ Example Templates\")\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [5, \"- Name: max 13 alphabets\\n- Phone Number: 10 digits\\n- Age: max 2 digits\\n- Occupation: max 30 alphabets\\n- PAN ID: 12 alphanumeric characters\", \"All Indian names\"],\n",
        "            [10, \"- Product Name: max 20 characters\\n- Price: between $10-$1000\\n- Category: Electronics/Clothing/Food\\n- Rating: 1-5 stars\\n- Stock: 0-500 units\", \"\"],\n",
        "            [8, \"- Customer Name: full name\\n- Email: valid email format\\n- Purchase Date: YYYY-MM-DD format\\n- Amount: $50-$5000\\n- Payment Method: Credit/Debit/PayPal\", \"Dates in 2024\"],\n",
        "        ],\n",
        "        inputs=[num_rows, columns_info, additional_constraints]\n",
        "    )\n",
        "\n",
        "    # Connect button\n",
        "    generate_btn.click(\n",
        "        fn=generate_dataset,\n",
        "        inputs=[num_rows, columns_info, additional_constraints],\n",
        "        outputs=[status_text, output_json, output_data]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "_8j2POM-SCjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLaunching Gradio interface...\")\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "kmcDh0cSSD5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "12Q1cP54SF2Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}