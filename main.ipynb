{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOKGntJg03AAUTRVcwox2ld",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rujjul/Synthetic_Dataset_Generator/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Synthetic_Dataset_Generator"
      ],
      "metadata": {
        "id": "AfuqJBVwAXjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "MUFzQjgIB-xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import os\n",
        "import requests\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "import gradio as gr\n",
        "import json"
      ],
      "metadata": {
        "id": "9A__7DHJAeAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LLM Model\n",
        "\n",
        "LLAMA = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""
      ],
      "metadata": {
        "id": "VhVABP1FDcF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Quant config\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "load_in_4bit=True,\n",
        "bnb_4bit_use_double_quant=True,\n",
        "bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "bnb_4bit_quant_type=\"nf4\"\n",
        ")"
      ],
      "metadata": {
        "id": "8vsysrRtMqna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(LLAMA)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(LLAMA, device_map=\"auto\", quantization_config=quant_config)"
      ],
      "metadata": {
        "id": "GDuB__KP4rJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "You are a helpful assistant who generates synthetic data based on the user's demand and scenario. The user will provide you with the number of rows, the column names with their respective data types, and some other parameters or constraints if necessary. If you are not able to provide any data regarding something just directly mention that you are unable to do so. Tehn the user will either update or modify their prompt. Do not provide a python script to generate the data. Provide the data as a json with arrays.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "FWxAl1sRD4cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#JSON Extraction Function\n",
        "\n",
        "def extract_json(text):\n",
        "    try:\n",
        "        data = json.loads(text)\n",
        "        return (\n",
        "            f\"âœ“ Successfully generated {len(data)} rows of data\",\n",
        "            json.dumps(data, indent=2),\n",
        "            data\n",
        "        )\n",
        "    except Exception as e:\n",
        "        return f\"âš  JSON parsing failed: {str(e)}\", text, None\n"
      ],
      "metadata": {
        "id": "TAGEASPR8h0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset Generation\n",
        "\n",
        "def generate_dataset(num_rows, columns_info, additional_constraints):\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "Create a synthetic dataset.\n",
        "\n",
        "Number of rows: {num_rows}\n",
        "\n",
        "Columns and constraints:\n",
        "{columns_info}\n",
        "\n",
        "Additional constraints:\n",
        "{additional_constraints}\n",
        "\n",
        "Notes:\n",
        "- Name: max 13 alphabets\n",
        "- Phone Number: exactly 10 digits\n",
        "- Age: max 2 digits\n",
        "- Occupation: max 30 alphabets\n",
        "- PAN ID: exactly 10 alphanumeric characters (ABCDE1234F format)\n",
        "Return ONLY JSON.\n",
        "\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        max_new_tokens=1500,\n",
        "        do_sample=True,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.decode(\n",
        "        outputs[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    assistant_response = decoded.split(\"assistant\")[-1].strip()\n",
        "\n",
        "    return extract_json(assistant_response)\n"
      ],
      "metadata": {
        "id": "NVTgEM948JuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(title=\"Synthetic Dataset Generator\") as demo:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ðŸŽ² Synthetic Dataset Generator\n",
        "    ### Powered by Llama 3.1 (4-bit quantized)\n",
        "    Generate custom synthetic datasets by specifying columns and constraints\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            num_rows = gr.Slider(\n",
        "                minimum=1,\n",
        "                maximum=100,\n",
        "                value=5,\n",
        "                step=1,\n",
        "                label=\"Number of Rows\"\n",
        "            )\n",
        "\n",
        "            columns_info = gr.Textbox(\n",
        "                label=\"Column Specifications\",\n",
        "                placeholder=\"Example:\\n- Name: max 13 alphabets\\n- Phone Number: 10 digits\\n- Age: max 2 digits\",\n",
        "                lines=8,\n",
        "                value=\"- Name: max 13 alphabets\\n- Phone Number: 10 digits\\n- Age: max 2 digits\\n- Occupation: max 30 alphabets\\n- PAN ID: 12 alphanumeric characters\"\n",
        "            )\n",
        "\n",
        "            additional_constraints = gr.Textbox(\n",
        "                label=\"Additional Constraints (Optional)\",\n",
        "                placeholder=\"Example: All names should be Indian names, Age between 18-65\",\n",
        "                lines=3\n",
        "            )\n",
        "\n",
        "            generate_btn = gr.Button(\"ðŸš€ Generate Dataset\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "        with gr.Column():\n",
        "            status_text = gr.Textbox(\n",
        "                label=\"Status\",\n",
        "                lines=2\n",
        "            )\n",
        "\n",
        "            output_json = gr.Code(\n",
        "                label=\"Generated Dataset (JSON)\",\n",
        "                language=\"json\",\n",
        "                lines=15\n",
        "            )\n",
        "\n",
        "            output_data = gr.JSON(\n",
        "                label=\"Preview\",\n",
        "                visible=True\n",
        "            )\n",
        "\n",
        "    # Examples\n",
        "    gr.Markdown(\"### ðŸ“‹ Example Templates\")\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [5, \"- Name: max 13 alphabets\\n- Phone Number: 10 digits\\n- Age: max 2 digits\\n- Occupation: max 30 alphabets\\n- PAN ID: 12 alphanumeric characters\", \"All Indian names\"],\n",
        "            [10, \"- Product Name: max 20 characters\\n- Price: between $10-$1000\\n- Category: Electronics/Clothing/Food\\n- Rating: 1-5 stars\\n- Stock: 0-500 units\", \"\"],\n",
        "            [8, \"- Customer Name: full name\\n- Email: valid email format\\n- Purchase Date: YYYY-MM-DD format\\n- Amount: $50-$5000\\n- Payment Method: Credit/Debit/PayPal\", \"Dates in 2024\"],\n",
        "        ],\n",
        "        inputs=[num_rows, columns_info, additional_constraints]\n",
        "    )\n",
        "\n",
        "    # Connect button\n",
        "    generate_btn.click(\n",
        "        fn=generate_dataset,\n",
        "        inputs=[num_rows, columns_info, additional_constraints],\n",
        "        outputs=[status_text, output_json, output_data]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "_8j2POM-SCjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLaunching Gradio interface...\")\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "kmcDh0cSSD5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "12Q1cP54SF2Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}